#coding=utf-8
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split, Dataset
from torchvision import datasets, transforms
import os
import sys
import shutil
from tqdm import tqdm
import math
import argparse # æ–°å¢

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path ä»¥ä¾¿å¯¼å…¥ model
current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.dirname(current_dir)
sys.path.append(root_dir)

from model.hanzi_tiny import HanziTiny  # ä¸“ç”¨çš„è½»é‡çº§æ±‰å­—è¯†åˆ«æ¨¡å‹

# ================= é…ç½®åŒºåŸŸ =================
# æ•°æ®é›†åœ¨æ ¹ç›®å½•ä¸‹
DATA_DIR = os.path.join(root_dir, "HWDB1.1", "subset_631")

def get_config():
    """æ ¹æ®ç¡¬ä»¶ç¯å¢ƒåŠ¨æ€è·å–é…ç½®"""
    parser = argparse.ArgumentParser(description='HanziTiny Training')
    parser.add_argument('--epochs', type=int, default=None, help='Number of epochs to train')
    parser.add_argument('--batch-size', type=int, default=None, help='Batch size')
    parser.add_argument('--patience', type=int, default=50, help='Early stopping patience')
    parser.add_argument('--optimizer', type=str, default='sgd', choices=['adamw', 'sgd'], help='Optimizer (sgd or adamw)')
    parser.add_argument('--lr', type=float, default=None, help='Learning rate')
    args = parser.parse_args()

    config = {}
    
    # HanziTiny æåº¦è½»é‡ï¼Œå³ä½¿åœ¨ CPU ä¸Šä¹Ÿå¾ˆå¿«ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥å¤§èƒ†ä¸€ç‚¹
    if torch.cuda.is_available():
        vram_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3
        if vram_gb > 8: 
            config['batch_size'] = 512
            config['num_workers'] = 8
            config['epochs'] = 200 # SGD éœ€è¦æ›´å¤šçš„è½®æ¬¡æ¥æ”¶æ•›
        else: 
            config['batch_size'] = 256
            config['num_workers'] = 4
            config['epochs'] = 150
    else:
        config['batch_size'] = 64
        config['num_workers'] = 0
        config['epochs'] = 5
    
    # å¦‚æœå‘½ä»¤è¡ŒæŒ‡å®šäº†å‚æ•°ï¼Œè¦†ç›–é»˜è®¤å€¼
    if args.epochs is not None:
        config['epochs'] = args.epochs
    if args.batch_size is not None:
        config['batch_size'] = args.batch_size
    
    # ä¼˜åŒ–å™¨é…ç½®
    config['optimizer'] = args.optimizer
    config['patience'] = args.patience
    
    # å­¦ä¹ ç‡è°ƒæ•´: SGD é€šå¸¸éœ€è¦æ¯” Adam å¤§å¾—å¤šçš„ LR
    if args.lr is not None:
        config['lr'] = args.lr
    else:
        # é»˜è®¤ LR
        if config['optimizer'] == 'sgd':
            config['lr'] = 0.1  # SGD åˆå§‹å­¦ä¹ ç‡é€šå¸¸è¾ƒå¤§ (0.1 ~ 0.05)
        else:
            config['lr'] = 2e-3 # AdamW
            
    config['img_size'] = 64
    
    # === åœæ­¢æ¡ä»¶ ===
    config['target_acc'] = 98.5    # ç›®æ ‡å‡†ç¡®ç‡
    
    return config

# ================= æ•°æ®é›†å·¥å…· =================

class TransformSubset(Dataset):
    def __init__(self, subset, transform=None):
        self.subset = subset
        self.transform = transform
    def __getitem__(self, index):
        x, y = self.subset[index]
        if self.transform:
            x = self.transform(x)
        return x, y
    def __len__(self):
        return len(self.subset)

def validate_and_cleanup_data_dir(data_dir):
    """ æ¸…ç†ç©ºæ–‡ä»¶å¤¹ï¼Œé¿å… ImageFolder æŠ¥é”™ """
    if not os.path.exists(data_dir):
        return
    
    removed_count = 0
    valid_exts = {'.jpg', '.jpeg', '.png', '.bmp', '.ppm', '.pgm', '.tif', '.tiff', '.webp'}
    subdirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]
    
    for class_name in subdirs:
        class_path = os.path.join(data_dir, class_name)
        has_valid_file = False
        for f in os.listdir(class_path):
            if os.path.splitext(f)[1].lower() in valid_exts:
                has_valid_file = True
                break
        
        if not has_valid_file:
            print(f"âš ï¸  ç±»åˆ« '{class_name}' ä¸ºç©ºï¼Œç§»é™¤...")
            try:
                shutil.rmtree(class_path)
                removed_count += 1
            except Exception as e:
                print(f"âŒ ç§»é™¤å¤±è´¥: {e}")
                
    if removed_count > 0:
        print(f"âœ… å·²æ¸…ç† {removed_count} ä¸ªç©ºç±»åˆ«ã€‚")

def safe_pil_loader(path):
    from PIL import Image
    try:
        with open(path, 'rb') as f:
            img = Image.open(f)
            return img.convert('L')
    except Exception as e:
        print(f"æ— æ³•è¯»å– {path}: {e}")
        return Image.new('L', (64, 64), color=0)

# ================= ä¸»ç¨‹åº =================

def main():
    config = get_config()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ å¯åŠ¨ HanziTiny è®­ç»ƒ | è®¾å¤‡: {device} | Batch: {config['batch_size']}")

    # æ•°æ®å¢å¼º
    train_transform = transforms.Compose([
        transforms.Resize((config['img_size'], config['img_size'])),
        transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.8, 1.2)), 
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5], std=[0.5]),
        transforms.RandomErasing(p=0.2, scale=(0.02, 0.1)) 
    ])

    val_transform = transforms.Compose([
        transforms.Resize((config['img_size'], config['img_size'])),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5], std=[0.5])
    ])

    # åŠ è½½æ•°æ®
    if not os.path.exists(DATA_DIR):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®é›† {DATA_DIR}")
        return

    validate_and_cleanup_data_dir(DATA_DIR)
    
    print("æ­£åœ¨åŠ è½½æ•°æ®é›†ç´¢å¼•...")
    full_dataset_raw = datasets.ImageFolder(root=DATA_DIR, loader=safe_pil_loader)
    num_classes = len(full_dataset_raw.classes)
    print(f"âœ… ç±»åˆ«æ•°: {num_classes}")

    # === å…³é”®ï¼šä¿å­˜ç±»åˆ«æ˜ å°„ï¼Œç¡®ä¿ GUI é¢„æµ‹æ—¶ç´¢å¼•ä¸€è‡´ ===
    import json
    # ä¿å­˜åˆ° checkpoints æ–‡ä»¶å¤¹
    checkpoints_dir = os.path.join(root_dir, "checkpoints")
    os.makedirs(checkpoints_dir, exist_ok=True)
    
    # ç±»åˆ«æ˜ å°„è·¯å¾„
    class_mapping_path = os.path.join(checkpoints_dir, "classes.json")
    # çŠ¶æ€è®°å½•è·¯å¾„ (è®°å½•æœ€ä½³å‡†ç¡®ç‡)
    status_path = os.path.join(checkpoints_dir, "train_status.json")
    
    with open(class_mapping_path, 'w', encoding='utf-8') as f:
        json.dump(full_dataset_raw.classes, f, ensure_ascii=False)
    print(f"ğŸ’¾ å·²ä¿å­˜ç±»åˆ«æ˜ å°„åˆ° {class_mapping_path}")

    train_size = int(0.85 * len(full_dataset_raw)) # å°æ¨¡å‹ä¸å®¹æ˜“è¿‡æ‹Ÿåˆï¼Œå¯ä»¥å¤šç»™ç‚¹è®­ç»ƒé›†
    val_size = len(full_dataset_raw) - train_size
    train_subset, val_subset = random_split(full_dataset_raw, [train_size, val_size])
    
    train_dataset = TransformSubset(train_subset, transform=train_transform)
    val_dataset = TransformSubset(val_subset, transform=val_transform)

    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, 
                              num_workers=config['num_workers'], pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False, 
                            num_workers=config['num_workers'], pin_memory=True)

    # åˆå§‹åŒ–æ¨¡å‹
    # æ¨¡å‹è·¯å¾„åœ¨ checkpoints
    model_path = os.path.join(checkpoints_dir, "best_hanzi_tiny.pth")
    model = HanziTiny(num_classes=num_classes).to(device)

    # === æ–­ç‚¹ç»­è®­é€»è¾‘ ===
    best_acc = 0.0
    
    if os.path.exists(model_path):
        print(f"ğŸ”„ å‘ç°ä¸Šæ¬¡è®­ç»ƒçš„æœ€ä½³æ¨¡å‹ {model_path}ï¼Œå‡†å¤‡åŠ è½½...")
        try:
            state_dict = torch.load(model_path, map_location=device)
            model.load_state_dict(state_dict)
            print("âœ… æˆåŠŸåŠ è½½æƒé‡")
            
            # ä¼˜å…ˆä» status.json è¯»å–ä¸Šæ¬¡çš„å‡†ç¡®ç‡ï¼Œé¿å…å› æ•°æ®é›†åˆ†å‰²ä¸åŒå¯¼è‡´çš„å„ç§æ³¢åŠ¨
            if os.path.exists(status_path):
                try:
                    with open(status_path, 'r') as f:
                        status = json.load(f)
                        best_acc = status.get('best_acc', 0.0)
                    print(f"ğŸ“Š ä»è®°å½•æ–‡ä»¶è¯»å–ä¸Šæ¬¡æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%")
                except:
                    print("âš ï¸ è¯»å– status.json å¤±è´¥ï¼Œå°†é‡æ–°è¯„ä¼°...")
                    best_acc = 0.0
            
            # å¦‚æœæ²¡æœ‰è®°å½•æˆ–ä¸º0ï¼Œå†å°è¯•æ‰‹åŠ¨è¯„ä¼° (ä½œä¸ºä¿åº•)
            if best_acc == 0:
                print("âš ï¸ æœªæ‰¾åˆ°å‡†ç¡®ç‡è®°å½•ï¼Œæ­£åœ¨é‡æ–°è¯„ä¼°å½“å‰éªŒè¯é›†åŸºå‡†...")
                model.eval()
                val_correct = 0
                val_total = 0
                with torch.no_grad():
                    for imgs, labels in val_loader:
                        imgs, labels = imgs.to(device), labels.to(device)
                        outputs = model(imgs)
                        _, predicted = outputs.max(1)
                        val_total += labels.size(0)
                        val_correct += predicted.eq(labels).sum().item()
                best_acc = 100. * val_correct / val_total
                print(f"ğŸ“Š å½“å‰æ¨¡å‹åŸºå‡†å‡†ç¡®ç‡: {best_acc:.2f}%")
            else:
                print(f"ğŸ“Š ç»§æ‰¿å†å²æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%")
            
            # ç»­è®­æ—¶ï¼Œå»ºè®®æŠŠå­¦ä¹ ç‡è°ƒå°ä¸€ç‚¹ï¼Œé˜²æ­¢éœ‡è¡
            # å¯¹äº SGDï¼Œå¦‚æœæ˜¯ç»­è®­ï¼Œå¯èƒ½ä¸éœ€è¦å‡åŠé‚£ä¹ˆæ¿€è¿›ï¼Œæˆ–è€…ä»ä¸€ä¸ªå°ä¸€ç‚¹çš„å€¼å¼€å§‹
            config['lr'] = config['lr'] * 0.5 
            print(f"ğŸ“‰ ç»­è®­æ¨¡å¼ï¼šå­¦ä¹ ç‡å·²è‡ªåŠ¨å‡åŠä¸º {config['lr']}")
            
        except Exception as e:
            print(f"âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥ ({e})ï¼Œå°†ä»å¤´å¼€å§‹è®­ç»ƒã€‚")
            best_acc = 0.0

    criterion = nn.CrossEntropyLoss()
    no_improve_epochs = 0 # è®°å½•å¤šå°‘è½®æ²¡æå‡
    
    # === ä¼˜åŒ–å™¨é€‰æ‹© ===
    print(f"ğŸ”§ ä½¿ç”¨ä¼˜åŒ–å™¨: {config['optimizer'].upper()} | LR: {config['lr']}")
    if config['optimizer'] == 'sgd':
        # SGD + Momentum æ˜¯ CNN åˆ·åˆ†çš„æ ‡é…
        # nesterov=True æœ‰æ—¶èƒ½åŠ é€Ÿæ”¶æ•›
        optimizer = optim.SGD(model.parameters(), lr=config['lr'], momentum=0.9, weight_decay=5e-4, nesterov=True)
    else:
        # AdamW
        optimizer = optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=1e-2)
    
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['epochs'])

    for epoch in range(config['epochs']):
        model.train()
        correct = 0
        total = 0
        loop = tqdm(train_loader, desc=f"Ep [{epoch+1}/{config['epochs']}]")
        
        for imgs, labels in loop:
            imgs, labels = imgs.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(imgs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
            loop.set_postfix(acc=f"{100.*correct/total:.1f}%", loss=f"{loss.item():.3f}")
            
        scheduler.step()
        
        # éªŒè¯
        model.eval()
        val_correct = 0
        val_total = 0
        with torch.no_grad():
            for imgs, labels in val_loader:
                imgs, labels = imgs.to(device), labels.to(device)
                outputs = model(imgs)
                _, predicted = outputs.max(1)
                val_total += labels.size(0)
                val_correct += predicted.eq(labels).sum().item()
        
        val_acc = 100. * val_correct / val_total
        print(f"   -> éªŒè¯é›†å‡†ç¡®ç‡: {val_acc:.2f}% (æœ€ä½³: {best_acc:.2f}%)")

        # 1. è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡æå‰åœæ­¢
        if val_acc >= config['target_acc']:
            print(f"\nğŸ¯ æ­å–œï¼æ¨¡å‹å·²è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡ {config['target_acc']}%ï¼Œæå‰ç»“æŸè®­ç»ƒï¼")
            if val_acc > best_acc:
                torch.save(model.state_dict(), model_path)
                with open(status_path, 'w') as f:
                    json.dump({'best_acc': val_acc}, f)
            break

        # 2. ä¿å­˜æœ€ä½³æ¨¡å‹ä¸æ—©åœè®¡æ•°
        if val_acc > best_acc:
            best_acc = val_acc
            no_improve_epochs = 0 # é‡ç½®è®¡æ•°å™¨
            torch.save(model.state_dict(), model_path)
            # ä¿å­˜çŠ¶æ€
            with open(status_path, 'w') as f:
                json.dump({'best_acc': val_acc}, f)
            print(f"   ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹è‡³ {model_path}")
        else:
            no_improve_epochs += 1
            print(f"   â³ æ€§èƒ½æœªæå‡ ({no_improve_epochs}/{config['patience']})")
        
        # 3. è§¦å‘æ—©åœ
        if no_improve_epochs >= config['patience']:
            print(f"\nğŸ›‘ æ—©åœè§¦å‘ï¼šéªŒè¯é›†å‡†ç¡®ç‡è¿ç»­ {config['patience']} è½®æœªæå‡ã€‚")
            print(f"   å½“å‰æœ€ä½³: {best_acc:.2f}%")
            break

    print("\nè®­ç»ƒç»“æŸã€‚")

if __name__ == '__main__':
    main()
